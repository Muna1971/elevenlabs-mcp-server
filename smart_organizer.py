#!/usr/bin/env python3
"""
ุณูุฑูุจุช ุชูุธูู ุฐูู ููููุงุช ุณุทุญ ุงูููุชุจ
ูุญูู ูุญุชูู ุงููููุงุช ููุตูููุง ุญุณุจ ุงูุณูุงู
"""

import os
import shutil
import re
from pathlib import Path
from typing import Optional, Tuple

# ูุญุงููุฉ ุงุณุชูุฑุงุฏ ุงูููุชุจุงุช ููุฑุงุกุฉ ุงููููุงุช
try:
    import PyPDF2
    HAS_PYPDF2 = True
except ImportError:
    HAS_PYPDF2 = False

try:
    from docx import Document
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False


# ==================== ุงูุชุตูููุงุช ูุงููููุงุช ุงูููุชุงุญูุฉ ====================

# ูููุงุช ููุชุงุญูุฉ ููุนูู (ุงูุชุนููู ุงููุณุชูุฑ)
WORK_KEYWORDS = {
    "general": [
        # ุงูุชุนููู ุงููุณุชูุฑ
        "ุชุนููู ูุณุชูุฑ", "ุงูุชุนููู ุงููุณุชูุฑ", "ูุฑูุฒ ุงูุชุนููู", "CEC", "LCEC", "LCEC-ADV",
        "ุชุฏุฑูุจ", "ุชุทููุฑ ูููู", "ูุฑุดุฉ ุนูู", "ุจุฑูุงูุฌ ุชุฏุฑูุจู", "ุฏูุฑุฉ", "ุฏูุฑุงุช",
        "continuing education", "professional development", "training", "workshop",
        # ุงูุดูุงุฏุงุช ูุงูุญุถูุฑ
        "ุดูุงุฏุฉ", "ุดูุงุฏุงุช", "certificate", "appreciation", "ุญุถูุฑ", "ุบูุงุจ", "attendance",
        # ุงูุฎุทุท ูุงูุชูุงุฑูุฑ
        "ุฎุทุฉ", "ุฎุทุท", "ุชุดุบูููุฉ", "plan", "ุชูุฑูุฑ", "report", "ุฅูุฌุงุฒุงุช", "ุฅูุฌุงุฒ",
        # ุงูุงุฌุชูุงุนุงุช ูุงููุจุงุฏุฑุงุช
        "ุงุฌุชูุงุน", "ูุญุถุฑ", "ูุจุงุฏุฑุฉ", "ูุจุงุฏุฑุงุช", "meeting",
        # ุงูุฌุงูุนุฉ
        "MBZUH", "ุฌุงูุนุฉ", "university", "ุฃูุงุฏููู",
        # ุฃุฎุฑู
        "ูููุฐุฌ", "ุงุณุชุจุงูุฉ", "ูุฑุดุญูู", "ูุฒุงุฑุฉ", "ูุนุงููุฉ", "ูุนุงููุงุช"
    ],
    "ุงููุบุฉ ุงูุนุฑุจูุฉ": [
        "ุงููุบุฉ ุงูุนุฑุจูุฉ", "ุงููุญู", "ุงูุตุฑู", "ุงูุจูุงุบุฉ", "arabic language",
        "ููุงุนุฏ ุงููุบุฉ", "ุงูุฅููุงุก", "ุงูุชุนุจูุฑ", "ุงูุฃุฏุจ ุงูุนุฑุจู"
    ],
    "ุงููุบุฉ ุงูุฅูุฌููุฒูุฉ": [
        "english", "ุงููุบุฉ ุงูุฅูุฌููุฒูุฉ", "grammar", "vocabulary",
        "IELTS", "TOEFL", "english course", "ุงูุฌููุฒู"
    ],
    "ุงููุบุฉ ุงููุฑูุณูุฉ": [
        "franรงais", "french", "ุงููุบุฉ ุงููุฑูุณูุฉ", "ูุฑูุณู", "grammaire"
    ],
    "ุงููุบุฉ ุงูุฃุฑุฏูุฉ": [
        "urdu", "ุงุฑุฏู", "ุงูุฃุฑุฏูุฉ", "ุงููุบุฉ ุงูุฃุฑุฏูุฉ", "ูพุงฺฉุณุชุงู", "ุงุฑุฏู ุฒุจุงู",
        "ูุณุชุนููู", "ุงุฑุฏู ุงุฏุจ", "pakistan", "urdu language"
    ],
    "ุงููุบุฉ ุงูุฑูุณูุฉ": [
        "russian", "ััััะบะธะน", "ุงูุฑูุณูุฉ", "ุงููุบุฉ ุงูุฑูุณูุฉ", "ุฑูุณู",
        "ัะพััะธั", "ััััะบะธะน ัะทัะบ", "russia", "russian language"
    ],
    "ูุดุฑูุนุงุช ูุชูุฑูุฉ": [
        "ูุดุฑูุน", "project", "ุฎุทุฉ", "plan", "ุชูุฑูุฑ", "report"
    ]
}

# ูููุงุช ููุชุงุญูุฉ ููุฏุฑุงุณุฉ (ุฑุณุงูุฉ ุงููุงุฌุณุชูุฑ - ุงููุณุงููุงุช ูุงูุฎุทุงุจ)
STUDY_KEYWORDS = [
    "ูุณุงููุงุช", "linguistics", "ุฎุทุงุจ", "discourse", "ุชุญููู ุงูุฎุทุงุจ",
    "discourse analysis", "ุณูููุงุฆูุฉ", "semiotics", "ุจุฑุงุบูุงุชูุฉ", "pragmatics",
    "ุตูุชูุงุช", "phonetics", "phonology", "morphology", "syntax",
    "semantics", "ุฏูุงูุฉ", "ุชุฏุงูููุฉ", "ูุธุฑูุฉ ุงููุบุฉ", "language theory",
    "ูุงุฌุณุชูุฑ", "ุฑุณุงูุชู", "ุฑุณุงูุฉ ุงููุงุฌุณุชูุฑ", "thesis", "ุจุญุซ ุนููู", "research",
    "ูููุฌูุฉ ุงูุจุญุซ", "methodology", "ุฃุทุฑูุญุฉ", "dissertation",
    "sociolinguistics", "ุนูู ุงููุบุฉ ุงูุงุฌุชูุงุนู", "psycholinguistics",
    "ูุต", "text", "textual", "ูุตู", "ุชุฃููู", "hermeneutics",
    "ุงููุตู ุงูุฃูู", "ุงููุตู ุงูุซุงูู", "ุงููุตู ุงูุซุงูุซ"
]

# ูููุงุช ููุชุงุญูุฉ ูู AIGO Center (ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุจุฒูุณ)
AIGO_KEYWORDS = [
    "ุฐูุงุก ุงุตุทูุงุนู", "artificial intelligence", "AI", "machine learning",
    "deep learning", "ุชุนูู ุขูู", "ุชุนูู ุนููู", "neural network",
    "ุดุจูุงุช ุนุตุจูุฉ", "python", "data science", "ุนูู ุงูุจูุงูุงุช",
    "chatbot", "GPT", "ChatGPT", "Claude", "prompt", "ุจุฑููุช",
    "automation", "ุฃุชูุชุฉ", "digital marketing", "ุชุณููู ุฑููู",
    "business", "ุจุฒูุณ", "startup", "ุฑูุงุฏุฉ", "entrepreneurship",
    "freelance", "ุนูู ุญุฑ", "online course", "ุฏูุฑุฉ ุฃูููุงูู",
    "AIGO", "consulting", "ุงุณุชุดุงุฑุงุช", "coaching", "ุชุฏุฑูุจ ุฐูุงุก",
    "ุงูููุงุฑุงุช ุงูุดุฎุตูุฉ", "ุงูุฐูุงุก ุงูุงุตุทูุงุนู"
]

# ุงูุชุฏุงุฏุงุช ุงููููุงุช
IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.ico', '.tiff']
VIDEO_EXTENSIONS = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.webm']
AUDIO_EXTENSIONS = ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.wma', '.m4a']
ARCHIVE_EXTENSIONS = ['.zip', '.rar', '.7z', '.tar', '.gz']
DOCUMENT_EXTENSIONS = ['.pdf', '.doc', '.docx', '.txt', '.md', '.rtf', '.ppt', '.pptx', '.xls', '.xlsx']
SHORTCUT_EXTENSIONS = ['.lnk', '.url']
HTML_EXTENSIONS = ['.html', '.htm']


# ==================== ุฏูุงู ูุฑุงุกุฉ ุงููููุงุช ====================

def read_pdf(file_path: Path) -> str:
    """ูุฑุงุกุฉ ูุญุชูู ููู PDF"""
    if not HAS_PYPDF2:
        return ""
    try:
        with open(file_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            text = ""
            for i, page in enumerate(reader.pages[:5]):
                text += page.extract_text() or ""
            return text
    except Exception:
        return ""


def read_docx(file_path: Path) -> str:
    """ูุฑุงุกุฉ ูุญุชูู ููู Word"""
    if not HAS_DOCX:
        return ""
    try:
        doc = Document(file_path)
        return "\n".join([para.text for para in doc.paragraphs[:50]])
    except Exception:
        return ""


def read_text(file_path: Path) -> str:
    """ูุฑุงุกุฉ ูุญุชูู ููู ูุตู"""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read(10000)
    except Exception:
        return ""


def get_file_content(file_path: Path) -> str:
    """ุงูุญุตูู ุนูู ูุญุชูู ุงูููู ุญุณุจ ููุนู"""
    suffix = file_path.suffix.lower()

    if suffix == '.pdf':
        return read_pdf(file_path)
    elif suffix in ['.docx', '.doc']:
        return read_docx(file_path)
    elif suffix in ['.txt', '.md', '.rtf']:
        return read_text(file_path)
    else:
        return file_path.stem


def analyze_filename(filename: str) -> str:
    """ุชุญููู ุงุณู ุงูููู ููุญุตูู ุนูู ูููุงุช ูููุฏุฉ"""
    name = Path(filename).stem
    name = re.sub(r'[_\-\.]', ' ', name)
    return name


# ==================== ุฏูุงู ุงูุชุตููู ====================

def count_keyword_matches(text: str, keywords: list) -> int:
    """ุญุณุงุจ ุนุฏุฏ ุงููููุงุช ุงูููุชุงุญูุฉ ุงูููุฌูุฏุฉ ูู ุงููุต"""
    text_lower = text.lower()
    count = 0
    for keyword in keywords:
        if keyword.lower() in text_lower:
            count += 1
    return count


def classify_by_extension(file_path: Path) -> Optional[str]:
    """ุชุตููู ุงูููู ุญุณุจ ุงูุงูุชุฏุงุฏ"""
    suffix = file_path.suffix.lower()
    name_lower = file_path.name.lower()

    # ุชุฌุงูู ุงูุงุฎุชุตุงุฑุงุช
    if suffix in SHORTCUT_EXTENSIONS:
        return "ุงุฎุชุตุงุฑุงุช"

    # ุงูุตูุฑ
    if suffix in IMAGE_EXTENSIONS:
        if "whatsapp" in name_lower:
            return "ุตูุฑ/ูุงุชุณุงุจ"
        elif "screenshot" in name_lower:
            return "ุตูุฑ/ููุทุงุช ุดุงุดุฉ"
        elif name_lower.startswith("img_"):
            return "ุตูุฑ/ูุงููุฑุง"
        else:
            return "ุตูุฑ/ุฃุฎุฑู"

    # ุงูููุฏูููุงุช
    if suffix in VIDEO_EXTENSIONS:
        if "whatsapp" in name_lower:
            return "ููุฏูููุงุช/ูุงุชุณุงุจ"
        else:
            return "ููุฏูููุงุช/ุฃุฎุฑู"

    # ุงูุตูุชูุงุช
    if suffix in AUDIO_EXTENSIONS:
        return "ุตูุชูุงุช"

    # ุงูุฃุฑุดููุงุช
    if suffix in ARCHIVE_EXTENSIONS:
        if "camscanner" in name_lower:
            return "ุงูุนูู/CamScanner"
        return "ุฃุฑุดููุงุช"

    # HTML
    if suffix in HTML_EXTENSIONS:
        return "ูููุงุช HTML"

    return None


def classify_file(file_path: Path) -> Tuple[str, Optional[str], Optional[str]]:
    """ุชุตููู ุงูููู ูุฅุฑุฌุงุน (ุงูุชุตููู ุงูุฑุฆูุณูุ ุงูุชุตููู ุงููุฑุนูุ ุงูุชุตููู ุงููุฑุนู ุงูุซุงูู)"""

    # ุฃููุงู: ุงูุชุตููู ุญุณุจ ุงูุงูุชุฏุงุฏ
    ext_category = classify_by_extension(file_path)
    if ext_category:
        parts = ext_category.split("/")
        if len(parts) == 2:
            return (parts[0], parts[1], None)
        return (parts[0], None, None)

    # ุซุงููุงู: ุงูุชุตููู ุญุณุจ ุงููุญุชูู (ูููุณุชูุฏุงุช)
    suffix = file_path.suffix.lower()
    if suffix not in DOCUMENT_EXTENSIONS:
        return ("ุบูุฑ ูุตูู", None, None)

    # ุงูุญุตูู ุนูู ุงููุญุชูู
    content = get_file_content(file_path)
    filename_text = analyze_filename(file_path.name)
    full_text = f"{filename_text} {content}"

    # ุญุณุงุจ ุงูุชุทุงุจูุงุช
    study_score = count_keyword_matches(full_text, STUDY_KEYWORDS)
    aigo_score = count_keyword_matches(full_text, AIGO_KEYWORDS)
    work_score = count_keyword_matches(full_text, WORK_KEYWORDS["general"])

    # ุชุญุฏูุฏ ุงูุชุตููู ุงูุฑุฆูุณู
    scores = {
        "ุฑุณุงูุฉ ุงููุงุฌุณุชูุฑ": study_score,
        "AIGO Center": aigo_score,
        "ุงูุนูู": work_score
    }

    max_category = max(scores, key=scores.get)
    max_score = scores[max_category]

    if max_score == 0:
        return ("ุบูุฑ ูุตูู", None, None)

    # ุชุตููู ูุฑุนู ููุนูู
    if max_category == "ุงูุนูู":
        subcategory = None
        sub_subcategory = None

        # ุชุญุฏูุฏ ูุณู ุงููุบุฉ
        lang_scores = {}
        for lang in ["ุงููุบุฉ ุงูุนุฑุจูุฉ", "ุงููุบุฉ ุงูุฅูุฌููุฒูุฉ", "ุงููุบุฉ ุงููุฑูุณูุฉ", "ุงููุบุฉ ุงูุฃุฑุฏูุฉ", "ุงููุบุฉ ุงูุฑูุณูุฉ"]:
            lang_scores[lang] = count_keyword_matches(full_text, WORK_KEYWORDS[lang])

        max_lang = max(lang_scores, key=lang_scores.get)
        if lang_scores[max_lang] > 0:
            subcategory = "ูุณู ุงููุบุงุช"
            sub_subcategory = max_lang
        else:
            if count_keyword_matches(full_text, WORK_KEYWORDS["ูุดุฑูุนุงุช ูุชูุฑูุฉ"]) > 0:
                subcategory = "ูุดุฑูุนุงุช ูุชูุฑูุฉ"

        return ("ุงูุนูู", subcategory, sub_subcategory)

    return (max_category, None, None)


# ==================== ุฏูุงู ุงูุชูุธูู ====================

def get_desktop_path() -> Path:
    """ุงูุญุตูู ุนูู ูุณุงุฑ ุณุทุญ ุงูููุชุจ"""
    home = Path.home()

    if os.name == 'nt':
        # ุงููุณุงุฑ ุงูุฎุงุต ุจู MBZUH
        mbzuh_desktop = home / "OneDrive - Mohamed Bin Zayed University for Humanities" / "MBZUH" / "OneDrive - Mohamed Bin Zayed University for Humanities" / "ุณุทุญ ุงูููุชุจ"
        if mbzuh_desktop.exists():
            return mbzuh_desktop

        # OneDrive ุงูุนุงุฏู
        onedrive_paths = [
            home / "OneDrive" / "Desktop",
            home / "OneDrive" / "ุณุทุญ ุงูููุชุจ",
            home / "OneDrive - Personal" / "Desktop",
        ]
        for path in onedrive_paths:
            if path.exists():
                return path

        # ุงููุณุงุฑ ุงูุนุงุฏู
        desktop = home / "Desktop"
        if not desktop.exists():
            desktop = home / "ุณุทุญ ุงูููุชุจ"
    else:
        desktop = home / "Desktop"
        if not desktop.exists():
            desktop = home / "ุณุทุญ ุงูููุชุจ"

    return desktop


def move_file(file_path: Path, destination_folder: Path) -> Path:
    """ููู ุงูููู ูุน ุงูุชุนุงูู ูุน ุงูุชูุฑุงุฑ"""
    destination_folder.mkdir(parents=True, exist_ok=True)
    destination = destination_folder / file_path.name

    if destination.exists():
        base = file_path.stem
        ext = file_path.suffix
        counter = 1
        while destination.exists():
            destination = destination_folder / f"{base}_{counter}{ext}"
            counter += 1

    shutil.move(str(file_path), str(destination))
    return destination


def organize_desktop(dry_run: bool = True, custom_path: str = None):
    """ุชูุธูู ูููุงุช ุงููุฌูุฏ ุงููุญุฏุฏ"""
    if custom_path:
        desktop = Path(custom_path)
    else:
        desktop = get_desktop_path()

    if not desktop.exists():
        print(f"โ ูู ูุชู ุงูุนุซูุฑ ุนูู ุงููุฌูุฏ: {desktop}")
        return

    print(f"๐ ูุณุงุฑ ุงููุฌูุฏ: {desktop}")
    print("=" * 60)

    print("\n๐ ุงูููุชุจุงุช ุงููุชุงุญุฉ:")
    print(f"   โข PyPDF2 (ููุฑุงุกุฉ PDF): {'โ' if HAS_PYPDF2 else 'โ ุบูุฑ ูุซุจุชุฉ'}")
    print(f"   โข python-docx (ููุฑุงุกุฉ Word): {'โ' if HAS_DOCX else 'โ ุบูุฑ ูุซุจุชุฉ'}")

    if not HAS_PYPDF2 or not HAS_DOCX:
        print("\n๐ก ูุชุซุจูุช ุงูููุชุจุงุช ุงูููููุฏุฉ:")
        print("   pip install PyPDF2 python-docx")

    print("\n" + "=" * 60)

    results = {}
    errors = []

    for item in desktop.iterdir():
        # ุชุฌุงูู ุงููุฌูุฏุงุช ูุงููููุงุช ุงููุฎููุฉ ูุงููููุงุช ุงููุคูุชุฉ
        if item.is_dir() or item.name.startswith('.') or item.name.startswith('~$'):
            continue

        try:
            # ุชุตููู ุงูููู
            main_cat, sub_cat, sub_sub_cat = classify_file(item)

            # ุจูุงุก ุงููุณุงุฑ
            if sub_cat:
                if sub_sub_cat:
                    dest_path = desktop / main_cat / sub_cat / sub_sub_cat
                else:
                    dest_path = desktop / main_cat / sub_cat
            else:
                dest_path = desktop / main_cat

            # ุนุฑุถ ุงููุชูุฌุฉ
            path_display = main_cat
            if sub_cat:
                path_display += f" / {sub_cat}"
            if sub_sub_cat:
                path_display += f" / {sub_sub_cat}"

            print(f"\n๐ {item.name}")
            print(f"   โ {path_display}")

            # ุชุณุฌูู ุงููุชูุฌุฉ
            if main_cat not in results:
                results[main_cat] = []
            results[main_cat].append(item.name)

            if not dry_run:
                move_file(item, dest_path)

        except Exception as e:
            errors.append(f"{item.name}: {str(e)}")
            print(f"\nโ ุฎุทุฃ ูู {item.name}: {str(e)}")

    # ููุฎุต
    print("\n" + "=" * 60)
    print("๐ ููุฎุต ุงูุชุตููู:")
    print("-" * 40)

    total = 0
    for category, files in sorted(results.items()):
        if files:
            print(f"\n๐ {category}: {len(files)} ููู")
            for f in files[:3]:
                print(f"   โข {f}")
            if len(files) > 3:
                print(f"   ... ู {len(files) - 3} ูููุงุช ุฃุฎุฑู")
            total += len(files)

    if errors:
        print(f"\nโ๏ธ ุฃุฎุทุงุก: {len(errors)}")

    print("\n" + "=" * 60)
    if dry_run:
        print("๐ ูุฐุง ุนุฑุถ ุชุฌุฑูุจู - ูู ูุชู ููู ุฃู ูููุงุช")
    else:
        print(f"โจ ุชู ุชูุธูู {total} ููู ุจูุฌุงุญ!")


# ==================== ุงูุชุดุบูู ====================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ุฃุฏุงุฉ ุงูุชูุธูู ุงูุฐูู ูููููุงุช')
    parser.add_argument('--run', action='store_true', help='ุชูููุฐ ุงูุชูุธูู ูุนููุงู')
    parser.add_argument('--path', type=str, help='ูุณุงุฑ ุงููุฌูุฏ ุงููุฑุงุฏ ุชูุธููู')
    args = parser.parse_args()

    print("\n" + "=" * 60)
    print("๐ง ุฃุฏุงุฉ ุงูุชูุธูู ุงูุฐูู ูููููุงุช")
    print("=" * 60)
    print("""
๐ ุงูุชุตูููุงุช:
   โโโ ุงูุนูู (ุงูุชุนููู ุงููุณุชูุฑ)
   โ   โโโ ูุณู ุงููุบุงุช (ุงูุนุฑุจูุฉุ ุงูุฅูุฌููุฒูุฉุ ุงููุฑูุณูุฉุ ุงูุฃุฑุฏูุฉุ ุงูุฑูุณูุฉ)
   โ   โโโ ูุดุฑูุนุงุช ูุชูุฑูุฉ
   โ   โโโ CamScanner
   โ
   โโโ ุฑุณุงูุฉ ุงููุงุฌุณุชูุฑ (ุงููุณุงููุงุช ูุงูุฎุทุงุจ)
   โ
   โโโ AIGO Center (ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุงูุจุฒูุณ)
   โ
   โโโ ุตูุฑ (ูุงุชุณุงุจุ ููุทุงุช ุดุงุดุฉุ ูุงููุฑุงุ ุฃุฎุฑู)
   โ
   โโโ ููุฏูููุงุช (ูุงุชุณุงุจุ ุฃุฎุฑู)
   โ
   โโโ ุฃุฑุดููุงุช
   โ
   โโโ ุบูุฑ ูุตูู
    """)

    if args.run:
        print("โก ุฌุงุฑู ุชูุธูู ุงููููุงุช...\n")
        organize_desktop(dry_run=False, custom_path=args.path)
    else:
        print("๐ ุนุฑุถ ุชุฌุฑูุจู:\n")
        organize_desktop(dry_run=True, custom_path=args.path)
        print("\n๐ก ูุชูููุฐ ุงูุชูุธูู ูุนููุงู:")
        if args.path:
            print(f'   python smart_organizer.py --path "{args.path}" --run')
        else:
            print("   python smart_organizer.py --run")
